{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‡ ç«¶é¦¬G1ãƒ‡ãƒ¼ã‚¿åé›†ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯\n",
      "ğŸ“š ãƒ©ã‚¤ãƒ–ãƒ©ãƒªèª­ã¿è¾¼ã¿ä¸­...\n",
      "âœ… ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«èª­ã¿è¾¼ã¿å®Œäº†\n",
      "ğŸ¯ æº–å‚™å®Œäº†ï¼\n"
     ]
    }
   ],
   "source": [
    "# ã‚»ãƒ«1: ç’°å¢ƒè¨­å®šã¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªèª­ã¿è¾¼ã¿\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "print(\"ğŸ‡ ç«¶é¦¬G1ãƒ‡ãƒ¼ã‚¿åé›†ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯\")\n",
    "print(\"ğŸ“š ãƒ©ã‚¤ãƒ–ãƒ©ãƒªèª­ã¿è¾¼ã¿ä¸­...\")\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "try:\n",
    "    from scraping.horse_list_scraper import G1HorseScraper  # â† ä¿®æ­£\n",
    "    print(\"âœ… ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«èª­ã¿è¾¼ã¿å®Œäº†\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "\n",
    "print(\"ğŸ¯ æº–å‚™å®Œäº†ï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'HorseListScraper' from 'scraping.horse_list_scraper' (/Users/skdata_mng/Documents/PROJECTS/STALLION/stallion-analytics/packages/ml-analysis/notebooks/../src/scraping/horse_list_scraper.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscraping\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhorse_list_scraper\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HorseListScraper\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'HorseListScraper' from 'scraping.horse_list_scraper' (/Users/skdata_mng/Documents/PROJECTS/STALLION/stallion-analytics/packages/ml-analysis/notebooks/../src/scraping/horse_list_scraper.py)"
     ]
    }
   ],
   "source": [
    "# ã‚»ãƒ«2: ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œï¼ˆãƒ†ã‚¹ãƒˆï¼‰\n",
    "print(\"ğŸš€ G1é¦¬ãƒ‡ãƒ¼ã‚¿ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚’é–‹å§‹ã—ã¾ã™...\")\n",
    "\n",
    "scraper = G1HorseScraper()\n",
    "horses = scraper.run(\n",
    "    max_horses=5,           # ãƒ†ã‚¹ãƒˆç”¨ã«5é ­ã®ã¿\n",
    "    min_birth_year=2018,    # 2018å¹´ä»¥é™ç”Ÿã¾ã‚Œ\n",
    "    save_to_db=True         # Supabaseã«ä¿å­˜\n",
    ")\n",
    "\n",
    "print(f\"ğŸ“Š {len(horses)}é ­ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«3: å–å¾—ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°ç¢ºèª\n",
    "print(\"ğŸ” å–å¾—ã—ãŸãƒ‡ãƒ¼ã‚¿ã®è©³ç´°:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for i, horse in enumerate(horses, 1):\n",
    "    print(f\"{i}. ID: {horse['id']}\")\n",
    "    print(f\"   åå‰: {horse['name_ja']}\")\n",
    "    print(f\"   æ€§åˆ¥: {horse['sex']}\")\n",
    "    print(f\"   ç”Ÿå¹´: {horse['birth_year']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«4: DataFrameåŒ–\n",
    "import pandas as pd\n",
    "\n",
    "print(\"ğŸ“ˆ ãƒ‡ãƒ¼ã‚¿ã‚’DataFrameã«å¤‰æ›...\")\n",
    "df = pd.DataFrame(horses)\n",
    "\n",
    "print(\"ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ æƒ…å ±:\")\n",
    "print(df.info())\n",
    "print(\"\\nåŸºæœ¬çµ±è¨ˆ:\")\n",
    "print(df.describe())\n",
    "print(\"\\nãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«5: ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãã§ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "filename = f\"../data/raw/g1_horses_sample_{timestamp}.json\"\n",
    "\n",
    "print(f\"ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜: {filename}\")\n",
    "\n",
    "# JSONãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜\n",
    "with open(filename, 'w', encoding='utf-8') as f:\n",
    "    json.dump(horses, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# CSVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ã‚‚ä¿å­˜\n",
    "csv_filename = f\"../data/raw/g1_horses_sample_{timestamp}.csv\"\n",
    "df.to_csv(csv_filename, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"âœ… JSON: {filename}\")\n",
    "print(f\"âœ… CSV: {csv_filename}\")\n",
    "print(\"ãƒ‡ãƒ¼ã‚¿ä¿å­˜å®Œäº†ï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

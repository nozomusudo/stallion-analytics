{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Supabase to PostgreSQL Migration\n",
    "# ç«¶é¦¬ãƒ‡ãƒ¼ã‚¿ã‚’Supabaseã‹ã‚‰ãƒ­ãƒ¼ã‚«ãƒ«PostgreSQLã«ç§»è¡Œ\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from psycopg2.extras import RealDictCursor\n",
    "from supabase import create_client, Client\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”Œ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’è¨­å®šä¸­...\n",
      "âœ… æ¥ç¶šè¨­å®šå®Œäº†\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 1. æ¥ç¶šè¨­å®š\n",
    "# =============================================================================\n",
    "\n",
    "print(\"ğŸ”Œ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’è¨­å®šä¸­...\")\n",
    "\n",
    "# Supabaseæ¥ç¶š\n",
    "supabase_url = os.getenv('NEXT_PUBLIC_SUPABASE_URL')\n",
    "supabase_key = os.getenv('SUPABASE_SERVICE_ROLE_KEY')\n",
    "supabase: Client = create_client(supabase_url, supabase_key)\n",
    "\n",
    "# PostgreSQLæ¥ç¶šè¨­å®š\n",
    "pg_config = {\n",
    "    'host': os.getenv('POSTGRES_HOST', 'localhost'),\n",
    "    'database': os.getenv('POSTGRES_DB', 'stallion_db'),\n",
    "    'user': os.getenv('POSTGRES_USER', 'stallion_user'),\n",
    "    'password': os.getenv('POSTGRES_PASSWORD'),\n",
    "    'port': int(os.getenv('POSTGRES_PORT', '5432'))\n",
    "}\n",
    "\n",
    "print(\"âœ… æ¥ç¶šè¨­å®šå®Œäº†\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ Supabaseã‹ã‚‰horsesãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...\n",
      "âœ… 692ä»¶ã®horsesãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—\n",
      "\n",
      "ğŸ“Š å–å¾—ã—ãŸãƒ‡ãƒ¼ã‚¿ã®æœ€åˆã®3ä»¶:\n",
      "  1. ID: 2019105213, Name: ãƒŠãƒŸãƒ¥ãƒ¼ãƒ«\n",
      "  2. ID: 2022105185, Name: ã‚¨ãƒ³ãƒ–ãƒ­ã‚¤ãƒ€ãƒªãƒ¼\n",
      "  3. ID: 2022103795, Name: ãƒŠãƒãƒ¥ãƒ©ãƒ«ãƒ©ã‚¤ã‚º\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 2. Supabaseã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—\n",
    "# =============================================================================\n",
    "\n",
    "def fetch_supabase_horses():\n",
    "    \"\"\"Supabaseã‹ã‚‰horsesãƒ‡ãƒ¼ã‚¿ã‚’å…¨ä»¶å–å¾—\"\"\"\n",
    "    print(\"ğŸ“¥ Supabaseã‹ã‚‰horsesãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...\")\n",
    "    \n",
    "    try:\n",
    "        # å…¨ä»¶å–å¾—ï¼ˆå¤§é‡ãƒ‡ãƒ¼ã‚¿ã®å ´åˆã¯ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³å¿…è¦ï¼‰\n",
    "        response = supabase.table('horses').select(\"*\").execute()\n",
    "        \n",
    "        if response.data:\n",
    "            print(f\"âœ… {len(response.data)}ä»¶ã®horsesãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—\")\n",
    "            return response.data\n",
    "        else:\n",
    "            print(\"âš ï¸ Supabaseã«horsesãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¾ã›ã‚“\")\n",
    "            return []\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Supabaseãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "        return []\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿å–å¾—å®Ÿè¡Œ\n",
    "supabase_horses = fetch_supabase_horses()\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ç¢ºèª\n",
    "if supabase_horses:\n",
    "    print(f\"\\nğŸ“Š å–å¾—ã—ãŸãƒ‡ãƒ¼ã‚¿ã®æœ€åˆã®3ä»¶:\")\n",
    "    for i, horse in enumerate(supabase_horses[:3]):\n",
    "        print(f\"  {i+1}. ID: {horse.get('id')}, Name: {horse.get('name_ja')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ§¹ ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ä¸­...\n",
      "âœ… 692ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 3. ãƒ‡ãƒ¼ã‚¿å¤‰æ›ãƒ»ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°\n",
    "# =============================================================================\n",
    "\n",
    "def clean_horse_data(horses_data):\n",
    "    \"\"\"ãƒ‡ãƒ¼ã‚¿ã‚’PostgreSQLç”¨ã«å¤‰æ›ãƒ»ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°\"\"\"\n",
    "    print(\"\\nğŸ§¹ ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ä¸­...\")\n",
    "    \n",
    "    cleaned_data = []\n",
    "    \n",
    "    for horse in horses_data:\n",
    "        # åŸºæœ¬çš„ãªã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°\n",
    "        cleaned_horse = {\n",
    "            'id': horse.get('id'),\n",
    "            'name_ja': horse.get('name_ja'),\n",
    "            'name_en': horse.get('name_en'),\n",
    "            'birth_date': horse.get('birth_date'),\n",
    "            'sex': horse.get('sex'),\n",
    "            'profile': json.dumps(horse.get('profile')) if horse.get('profile') else None,\n",
    "            'sire_id': horse.get('sire_id'),\n",
    "            'dam_id': horse.get('dam_id'),\n",
    "            'maternal_grandsire_id': horse.get('maternal_grandsire_id'),\n",
    "            'created_at': horse.get('created_at'),\n",
    "            'updated_at': horse.get('updated_at')\n",
    "        }\n",
    "        \n",
    "        # Noneå€¤ã‚„ç©ºæ–‡å­—ã®å‡¦ç†\n",
    "        for key, value in cleaned_horse.items():\n",
    "            if value == '' or value == 'null':\n",
    "                cleaned_horse[key] = None\n",
    "        \n",
    "        cleaned_data.append(cleaned_horse)\n",
    "    \n",
    "    print(f\"âœ… {len(cleaned_data)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†\")\n",
    "    return cleaned_data\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ\n",
    "if supabase_horses:\n",
    "    cleaned_horses = clean_horse_data(supabase_horses)\n",
    "else:\n",
    "    cleaned_horses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š å–å¾—ã—ãŸãƒ‡ãƒ¼ã‚¿ã®æœ€åˆã®3ä»¶:\n",
      "{'id': '2019105213', 'name_ja': 'ãƒŠãƒŸãƒ¥ãƒ¼ãƒ«', 'name_en': 'Namur', 'birth_date': '2019-03-02', 'sex': 'mare', 'profile': '{\"owner\": \"\\\\u30ad\\\\u30e3\\\\u30ed\\\\u30c3\\\\u30c8\\\\u30d5\\\\u30a1\\\\u30fc\\\\u30e0\", \"breeder\": \"\\\\u30ce\\\\u30fc\\\\u30b6\\\\u30f3\\\\u30d5\\\\u30a1\\\\u30fc\\\\u30e0\", \"trainer\": \"\\\\u9ad8\\\\u91ce\\\\u53cb\\\\u548c(\\\\u6817\\\\u6771)\", \"birthplace\": \"\\\\u5b89\\\\u5e73\\\\u753a\", \"career_record\": {\"wins\": 5, \"first\": 5, \"third\": 2, \"others\": 7, \"second\": 4, \"starts\": 18, \"win_rate\": 27.8}, \"offering_info\": {\"raw_text\": \"1\\\\u53e3:6.5\\\\u4e07\\\\u5186/400\\\\u53e3\"}, \"related_horses\": \"\\\\u30e9\\\\u30f4\\\\u30a7\\\\u30eb\\\\u3001\\\\u30f4\\\\u30a7\\\\u30b9\\\\u30bf\\\\u30fc\\\\u30f4\\\\u30a1\\\\u30eb\\\\u30c8\", \"total_prize_central\": 50963}', 'sire_id': '000a011996', 'dam_id': '2010104050', 'maternal_grandsire_id': '2001103114', 'created_at': '2025-08-23T07:09:57.679334', 'updated_at': '2025-08-23T08:50:10.980668'}\n",
      "{'id': '2022105185', 'name_ja': 'ã‚¨ãƒ³ãƒ–ãƒ­ã‚¤ãƒ€ãƒªãƒ¼', 'name_en': 'Embroidery', 'birth_date': '2022-02-01', 'sex': 'mare', 'profile': '{\"owner\": \"\\\\u30b7\\\\u30eb\\\\u30af\\\\u30ec\\\\u30fc\\\\u30b7\\\\u30f3\\\\u30b0\", \"breeder\": \"\\\\u30ce\\\\u30fc\\\\u30b6\\\\u30f3\\\\u30d5\\\\u30a1\\\\u30fc\\\\u30e0\", \"trainer\": \"\\\\u68ee\\\\u4e00\\\\u8aa0(\\\\u7f8e\\\\u6d66)\", \"birthplace\": \"\\\\u5b89\\\\u5e73\\\\u753a\", \"career_record\": {\"wins\": 4, \"first\": 4, \"third\": 0, \"others\": 2, \"second\": 1, \"starts\": 7, \"win_rate\": 57.1}, \"offering_info\": {\"raw_text\": \"1\\\\u53e3:6\\\\u4e07\\\\u5186/500\\\\u53e3\", \"total_units\": 500, \"price_per_unit\": 6}, \"related_horses\": \"\\\\u30bc\\\\u30fc\\\\u30bc\\\\u30de\\\\u30f3\\\\u3001\\\\u30d0\\\\u30fc\\\\u30c8\\\\u30e9\\\\u30ac\\\\u30c3\\\\u30c4\", \"total_prize_central\": 20455}', 'sire_id': '2016104422', 'dam_id': '2013105783', 'maternal_grandsire_id': '1998110135', 'created_at': '2025-08-23T07:52:39.815626', 'updated_at': '2025-08-23T08:46:25.811643'}\n",
      "{'id': '2022103795', 'name_ja': 'ãƒŠãƒãƒ¥ãƒ©ãƒ«ãƒ©ã‚¤ã‚º', 'name_en': 'Natural Rise', 'birth_date': '2022-02-02', 'sex': 'stallion', 'profile': '{\"owner\": \"\\\\u5409\\\\u5ca1\\\\u5bdb\\\\u884c\", \"breeder\": \"\\\\u30b0\\\\u30e9\\\\u30f3\\\\u30c9\\\\u7267\\\\u5834\", \"trainer\": \"\\\\u4f0a\\\\u85e4\\\\u572d\\\\u4e09(\\\\u7f8e\\\\u6d66)\", \"birthplace\": \"\\\\u65b0\\\\u3072\\\\u3060\\\\u304b\\\\u753a\", \"auction_price\": \"3,630\\\\u4e07\\\\u5186(2022\\\\u5e74 \\\\u30bb\\\\u30ec\\\\u30af\\\\u30c8\\\\u30bb\\\\u30fc\\\\u30eb)\", \"career_record\": {\"wins\": 5, \"first\": 5, \"third\": 0, \"others\": 1, \"second\": 0, \"starts\": 6, \"win_rate\": 83.3}, \"related_horses\": \"\\\\u30ec\\\\u30c7\\\\u30a3\\\\u30de\\\\u30c9\\\\u30f3\\\\u30ca\\\\u306e2025\\\\u3001\\\\u30a2\\\\u30c8\\\\u30e9\\\\u30c3\\\\u30d7\\\\u30e2\\\\u30a2\", \"total_prize_local\": 10420, \"total_prize_central\": 2354}', 'sire_id': '2010105827', 'dam_id': '2016105687', 'maternal_grandsire_id': '000a0022ea', 'created_at': '2025-08-23T07:52:36.299771', 'updated_at': '2025-08-23T08:46:21.173476'}\n"
     ]
    }
   ],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿ç¢ºèª\n",
    "if cleaned_horses:\n",
    "    print(f\"\\nğŸ“Š å–å¾—ã—ãŸãƒ‡ãƒ¼ã‚¿ã®æœ€åˆã®3ä»¶:\")\n",
    "    for i, horse in enumerate(cleaned_horses[:3]):\n",
    "        print(horse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”— PostgreSQLæ¥ç¶šãƒ†ã‚¹ãƒˆä¸­...\n",
      "æ¥ç¶šä¸­ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹: stallion_db\n",
      "æ¥ç¶šä¸­ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼: keiba_user\n",
      "publicã‚¹ã‚­ãƒ¼ãƒå†…ã®ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§: ['horses']\n",
      "âœ… horsesãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã—ã¾ã™\n",
      "horsesãƒ†ãƒ¼ãƒ–ãƒ«ã®è¡Œæ•°: 3\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 4. PostgreSQLã¸ã®æ¥ç¶šãƒ†ã‚¹ãƒˆ\n",
    "# =============================================================================\n",
    "\n",
    "def test_postgresql_connection():\n",
    "    \"\"\"PostgreSQLæ¥ç¶šãƒ†ã‚¹ãƒˆï¼ˆè©³ç´°ç‰ˆï¼‰\"\"\"\n",
    "    print(\"ğŸ”— PostgreSQLæ¥ç¶šãƒ†ã‚¹ãƒˆä¸­...\")\n",
    "    \n",
    "    try:\n",
    "        conn = psycopg2.connect(**pg_config)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # ç¾åœ¨æ¥ç¶šã—ã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç¢ºèª\n",
    "        cursor.execute(\"SELECT current_database();\")\n",
    "        current_db = cursor.fetchone()[0]\n",
    "        print(f\"æ¥ç¶šä¸­ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹: {current_db}\")\n",
    "        \n",
    "        # ç¾åœ¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ç¢ºèª\n",
    "        cursor.execute(\"SELECT current_user;\")\n",
    "        current_user = cursor.fetchone()[0]\n",
    "        print(f\"æ¥ç¶šä¸­ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼: {current_user}\")\n",
    "        \n",
    "        # å…¨ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§ç¢ºèª\n",
    "        cursor.execute(\"SELECT table_name FROM information_schema.tables WHERE table_schema = 'public';\")\n",
    "        tables = cursor.fetchall()\n",
    "        print(f\"publicã‚¹ã‚­ãƒ¼ãƒå†…ã®ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§: {[t[0] for t in tables]}\")\n",
    "        \n",
    "        # horsesãƒ†ãƒ¼ãƒ–ãƒ«å­˜åœ¨ç¢ºèª\n",
    "        cursor.execute(\"SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'horses');\")\n",
    "        table_exists = cursor.fetchone()[0]\n",
    "        \n",
    "        if table_exists:\n",
    "            print(\"âœ… horsesãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã—ã¾ã™\")\n",
    "            \n",
    "            # ãƒ†ãƒ¼ãƒ–ãƒ«è©³ç´°ç¢ºèª\n",
    "            cursor.execute(\"SELECT COUNT(*) FROM horses;\")\n",
    "            count = cursor.fetchone()[0]\n",
    "            print(f\"horsesãƒ†ãƒ¼ãƒ–ãƒ«ã®è¡Œæ•°: {count}\")\n",
    "        else:\n",
    "            print(\"âŒ horsesãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“\")\n",
    "        \n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        return table_exists\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ PostgreSQLæ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "        return False\n",
    "\n",
    "# æ¥ç¶šãƒ†ã‚¹ãƒˆå®Ÿè¡Œ\n",
    "pg_ready = test_postgresql_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“¤ 692ä»¶ã®horsesãƒ‡ãƒ¼ã‚¿ã‚’PostgreSQLã«ç§»è¡Œä¸­...\n",
      "  100ä»¶å‡¦ç†å®Œäº†...\n",
      "  200ä»¶å‡¦ç†å®Œäº†...\n",
      "  300ä»¶å‡¦ç†å®Œäº†...\n",
      "  400ä»¶å‡¦ç†å®Œäº†...\n",
      "  500ä»¶å‡¦ç†å®Œäº†...\n",
      "  600ä»¶å‡¦ç†å®Œäº†...\n",
      "\n",
      "âœ… ç§»è¡Œå®Œäº†: 692ä»¶æˆåŠŸ, 0ä»¶ã‚¨ãƒ©ãƒ¼\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 5. ãƒ‡ãƒ¼ã‚¿ç§»è¡Œå®Ÿè¡Œ\n",
    "# =============================================================================\n",
    "\n",
    "def migrate_horses_to_postgresql(horses_data):\n",
    "    \"\"\"horsesãƒ‡ãƒ¼ã‚¿ã‚’PostgreSQLã«ç§»è¡Œ\"\"\"\n",
    "    print(f\"\\nğŸ“¤ {len(horses_data)}ä»¶ã®horsesãƒ‡ãƒ¼ã‚¿ã‚’PostgreSQLã«ç§»è¡Œä¸­...\")\n",
    "    \n",
    "    if not horses_data:\n",
    "        print(\"ç§»è¡Œã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        conn = psycopg2.connect(**pg_config)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿å‰Šé™¤ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰\n",
    "        # cursor.execute(\"TRUNCATE horses CASCADE;\")\n",
    "        \n",
    "        success_count = 0\n",
    "        error_count = 0\n",
    "        \n",
    "        for horse in horses_data:\n",
    "            try:\n",
    "                # UPSERTï¼ˆå­˜åœ¨ã™ã‚Œã°æ›´æ–°ã€ãªã‘ã‚Œã°æŒ¿å…¥ï¼‰\n",
    "                upsert_query = \"\"\"\n",
    "                INSERT INTO horses (id, name_ja, name_en, birth_date, sex, profile, \n",
    "                                  sire_id, dam_id, maternal_grandsire_id, created_at, updated_at)\n",
    "                VALUES (%(id)s, %(name_ja)s, %(name_en)s, %(birth_date)s, %(sex)s, %(profile)s,\n",
    "                       %(sire_id)s, %(dam_id)s, %(maternal_grandsire_id)s, %(created_at)s, %(updated_at)s)\n",
    "                ON CONFLICT (id) DO UPDATE SET\n",
    "                    name_ja = EXCLUDED.name_ja,\n",
    "                    name_en = EXCLUDED.name_en,\n",
    "                    birth_date = EXCLUDED.birth_date,\n",
    "                    sex = EXCLUDED.sex,\n",
    "                    profile = EXCLUDED.profile,\n",
    "                    sire_id = EXCLUDED.sire_id,\n",
    "                    dam_id = EXCLUDED.dam_id,\n",
    "                    maternal_grandsire_id = EXCLUDED.maternal_grandsire_id,\n",
    "                    updated_at = EXCLUDED.updated_at;\n",
    "                \"\"\"\n",
    "                \n",
    "                cursor.execute(upsert_query, horse)\n",
    "                success_count += 1\n",
    "                \n",
    "                if success_count % 100 == 0:\n",
    "                    print(f\"  {success_count}ä»¶å‡¦ç†å®Œäº†...\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                error_count += 1\n",
    "                print(f\"  âš ï¸ ãƒ‡ãƒ¼ã‚¿æŒ¿å…¥ã‚¨ãƒ©ãƒ¼ (ID: {horse.get('id')}): {e}\")\n",
    "        \n",
    "        conn.commit()\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        \n",
    "        print(f\"\\nâœ… ç§»è¡Œå®Œäº†: {success_count}ä»¶æˆåŠŸ, {error_count}ä»¶ã‚¨ãƒ©ãƒ¼\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ç§»è¡Œã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "        return False\n",
    "\n",
    "# ç§»è¡Œå®Ÿè¡Œ\n",
    "if cleaned_horses and pg_ready:\n",
    "    migration_success = migrate_horses_to_postgresql(cleaned_horses)\n",
    "else:\n",
    "    print(\"ç§»è¡Œæ¡ä»¶ãŒæº€ãŸã•ã‚Œã¦ã„ã¾ã›ã‚“\")\n",
    "    migration_success = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ Supabaseã‹ã‚‰horse_relationsãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...\n",
      "âœ… 1000ä»¶ã®horse_relationsãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—\n",
      "\n",
      "ğŸ§¹ horse_relationsãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ä¸­...\n",
      "âœ… 1000ä»¶ã®relationsãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†\n",
      "\n",
      "ğŸ“¤ 1000ä»¶ã®horse_relationsãƒ‡ãƒ¼ã‚¿ã‚’PostgreSQLã«ç§»è¡Œä¸­...\n",
      "  100ä»¶å‡¦ç†å®Œäº†...\n",
      "  200ä»¶å‡¦ç†å®Œäº†...\n",
      "  300ä»¶å‡¦ç†å®Œäº†...\n",
      "  400ä»¶å‡¦ç†å®Œäº†...\n",
      "  500ä»¶å‡¦ç†å®Œäº†...\n",
      "  600ä»¶å‡¦ç†å®Œäº†...\n",
      "  700ä»¶å‡¦ç†å®Œäº†...\n",
      "  800ä»¶å‡¦ç†å®Œäº†...\n",
      "  900ä»¶å‡¦ç†å®Œäº†...\n",
      "  1000ä»¶å‡¦ç†å®Œäº†...\n",
      "\n",
      "âœ… ç§»è¡Œå®Œäº†: 1000ä»¶æˆåŠŸ, 0ä»¶ã‚¨ãƒ©ãƒ¼\n",
      "ğŸ“Š PostgreSQLã®horse_relationsãƒ†ãƒ¼ãƒ–ãƒ«: 1000ä»¶\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# horse_relationsç§»è¡Œç”¨ã®é–¢æ•°ã‚’è¿½åŠ \n",
    "# =============================================================================\n",
    "\n",
    "def fetch_supabase_horse_relations():\n",
    "    \"\"\"Supabaseã‹ã‚‰horse_relationsãƒ‡ãƒ¼ã‚¿ã‚’å…¨ä»¶å–å¾—ï¼ˆãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³å¯¾å¿œï¼‰\"\"\"\n",
    "    print(\"ğŸ“¥ Supabaseã‹ã‚‰horse_relationsãƒ‡ãƒ¼ã‚¿ã‚’å…¨ä»¶å–å¾—ä¸­...\")\n",
    "    \n",
    "    all_data = []\n",
    "    page_size = 1000\n",
    "    offset = 0\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            response = supabase.table('horse_relations').select(\"*\").range(offset, offset + page_size - 1).execute()\n",
    "            \n",
    "            if not response.data:\n",
    "                break\n",
    "            \n",
    "            all_data.extend(response.data)\n",
    "            print(f\"  {len(all_data)}ä»¶å–å¾—å®Œäº†...\")\n",
    "            \n",
    "            # å–å¾—ä»¶æ•°ãŒpage_sizeã‚ˆã‚Šå°‘ãªã„å ´åˆã¯æœ€å¾Œã®ãƒšãƒ¼ã‚¸\n",
    "            if len(response.data) < page_size:\n",
    "                break\n",
    "            \n",
    "            offset += page_size\n",
    "        \n",
    "        print(f\"âœ… åˆè¨ˆ{len(all_data)}ä»¶ã®horse_relationsãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—\")\n",
    "        return all_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Supabaseãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "        return all_data  # éƒ¨åˆ†çš„ã«å–å¾—ã§ããŸãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™\n",
    "\n",
    "def clean_horse_relations_data(relations_data):\n",
    "    \"\"\"horse_relationsãƒ‡ãƒ¼ã‚¿ã‚’PostgreSQLç”¨ã«å¤‰æ›\"\"\"\n",
    "    print(f\"\\nğŸ§¹ horse_relationsãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ä¸­...\")\n",
    "    \n",
    "    cleaned_data = []\n",
    "    \n",
    "    for relation in relations_data:\n",
    "        cleaned_relation = {\n",
    "            'horse_a_id': relation.get('horse_a_id'),\n",
    "            'horse_b_id': relation.get('horse_b_id'),\n",
    "            'relation_type': relation.get('relation_type'),\n",
    "            'children_ids': relation.get('children_ids'),  # é…åˆ—ã¯ãã®ã¾ã¾\n",
    "            'created_at': relation.get('created_at')\n",
    "        }\n",
    "        \n",
    "        # Noneå€¤å‡¦ç†\n",
    "        for key, value in cleaned_relation.items():\n",
    "            if value == '' or value == 'null':\n",
    "                cleaned_relation[key] = None\n",
    "        \n",
    "        cleaned_data.append(cleaned_relation)\n",
    "    \n",
    "    print(f\"âœ… {len(cleaned_data)}ä»¶ã®relationsãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†\")\n",
    "    return cleaned_data\n",
    "\n",
    "def migrate_horse_relations_to_postgresql(relations_data):\n",
    "    \"\"\"horse_relationsãƒ‡ãƒ¼ã‚¿ã‚’PostgreSQLã«ç§»è¡Œ\"\"\"\n",
    "    print(f\"\\nğŸ“¤ {len(relations_data)}ä»¶ã®horse_relationsãƒ‡ãƒ¼ã‚¿ã‚’PostgreSQLã«ç§»è¡Œä¸­...\")\n",
    "    \n",
    "    if not relations_data:\n",
    "        print(\"ç§»è¡Œã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        conn = psycopg2.connect(**pg_config)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        success_count = 0\n",
    "        error_count = 0\n",
    "        \n",
    "        for relation in relations_data:\n",
    "            try:\n",
    "                # UPSERTï¼ˆidã¯è‡ªå‹•æ¡ç•ªã®ãŸã‚ã€é‡è¤‡ãƒã‚§ãƒƒã‚¯ã¯ä»–ã®æ¡ä»¶ã§ï¼‰\n",
    "                upsert_query = \"\"\"\n",
    "                INSERT INTO horse_relations (horse_a_id, horse_b_id, relation_type, children_ids, created_at)\n",
    "                VALUES (%(horse_a_id)s, %(horse_b_id)s, %(relation_type)s, %(children_ids)s, %(created_at)s)\n",
    "                ON CONFLICT DO NOTHING;\n",
    "                \"\"\"\n",
    "                \n",
    "                cursor.execute(upsert_query, relation)\n",
    "                success_count += 1\n",
    "                \n",
    "                if success_count % 100 == 0:\n",
    "                    print(f\"  {success_count}ä»¶å‡¦ç†å®Œäº†...\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                error_count += 1\n",
    "                print(f\"  âš ï¸ ãƒ‡ãƒ¼ã‚¿æŒ¿å…¥ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "        \n",
    "        conn.commit()\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        \n",
    "        print(f\"\\nâœ… ç§»è¡Œå®Œäº†: {success_count}ä»¶æˆåŠŸ, {error_count}ä»¶ã‚¨ãƒ©ãƒ¼\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ç§»è¡Œã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "        return False\n",
    "\n",
    "# horse_relationsç§»è¡Œå®Ÿè¡Œ\n",
    "supabase_relations = fetch_supabase_horse_relations()\n",
    "\n",
    "if supabase_relations:\n",
    "    cleaned_relations = clean_horse_relations_data(supabase_relations)\n",
    "    relations_migration_success = migrate_horse_relations_to_postgresql(cleaned_relations)\n",
    "else:\n",
    "    relations_migration_success = False\n",
    "\n",
    "# çµæœç¢ºèª\n",
    "if relations_migration_success:\n",
    "    try:\n",
    "        conn = psycopg2.connect(**pg_config)\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"SELECT COUNT(*) FROM horse_relations;\")\n",
    "        count = cursor.fetchone()[0]\n",
    "        print(f\"ğŸ“Š PostgreSQLã®horse_relationsãƒ†ãƒ¼ãƒ–ãƒ«: {count}ä»¶\")\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "    except Exception as e:\n",
    "        print(f\"ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

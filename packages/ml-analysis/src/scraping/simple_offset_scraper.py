# ã‚·ãƒ³ãƒ—ãƒ«ãªã‚ªãƒ•ã‚»ãƒƒãƒˆæ–¹å¼ã§ã®é¦¬ãƒªã‚¹ãƒˆå–å¾—
# ç¢ºå®Ÿã«é‡è¤‡ãªãå¤§é‡ãƒ‡ãƒ¼ã‚¿ã‚’åé›†

import requests
from bs4 import BeautifulSoup
import time
import math
from typing import List, Dict, Optional
import json
import os
from datetime import datetime

class SimpleOffsetHorseListScraper:
    """ã‚·ãƒ³ãƒ—ãƒ«ãªã‚ªãƒ•ã‚»ãƒƒãƒˆæ–¹å¼ã§G1é¦¬ãƒªã‚¹ãƒˆã‚’å–å¾—"""
    
    def __init__(self):
        self.base_url = "https://db.netkeiba.com/horse/list.html"
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
    
    def get_g1_horses_by_offset(
        self, 
        offset: int = 0,
        max_horses: int = 100,
        min_birth_year: int = 2015,
        per_page: int = 100
    ) -> List[Dict]:
        """
        ã‚ªãƒ•ã‚»ãƒƒãƒˆæ–¹å¼ã§G1é¦¬ã‚’å–å¾—
        
        Args:
            offset: é–‹å§‹ä½ç½®ï¼ˆ0ã‹ã‚‰ï¼‰
            max_horses: å–å¾—ã™ã‚‹æœ€å¤§é¦¬æ•°
            min_birth_year: æœ€å°ç”Ÿå¹´ï¼ˆã“ã‚Œã‚ˆã‚Šå¤ã„é¦¬ãŒå‡ºãŸã‚‰çµ‚äº†ï¼‰
            per_page: 1ãƒšãƒ¼ã‚¸ã‚ãŸã‚Šã®é¦¬æ•°ï¼ˆ100å›ºå®šï¼‰
        
        Returns:
            é¦¬ã®ãƒªã‚¹ãƒˆ
        """
        print(f"ğŸ¯ G1é¦¬å–å¾—é–‹å§‹:")
        print(f"   ã‚ªãƒ•ã‚»ãƒƒãƒˆ: {offset}")
        print(f"   æœ€å¤§å–å¾—æ•°: {max_horses}é ­")
        print(f"   æœ€å°ç”Ÿå¹´: {min_birth_year}å¹´")
        print("-" * 50)
        
        # ãƒšãƒ¼ã‚¸è¨ˆç®—
        start_page = (offset // per_page) + 1
        start_position = offset % per_page
        
        horses = []
        current_page = start_page
        horses_collected = 0
        position_in_page = start_position
        
        print(f"ğŸ“„ é–‹å§‹ãƒšãƒ¼ã‚¸: {current_page}, ãƒšãƒ¼ã‚¸å†…ä½ç½®: {start_position}")
        
        while horses_collected < max_horses:
            print(f"\nğŸ“„ ãƒšãƒ¼ã‚¸{current_page}ã‚’å‡¦ç†ä¸­...")
            
            # ãƒšãƒ¼ã‚¸ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            page_horses = self._get_page_horses(current_page, per_page)
            
            if not page_horses:
                print("âŒ ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
                break
            
            # ãƒšãƒ¼ã‚¸å†…ã®æŒ‡å®šä½ç½®ã‹ã‚‰å‡¦ç†é–‹å§‹
            for i in range(position_in_page, len(page_horses)):
                horse = page_horses[i]
                
                # ç”Ÿå¹´ãƒã‚§ãƒƒã‚¯
                if horse['birth_year'] < min_birth_year:
                    print(f"â¹ï¸ ç”Ÿå¹´{horse['birth_year']}å¹´ã®{horse['name_ja']}ã«åˆ°é”ã€‚å‡¦ç†çµ‚äº†")
                    return horses
                
                horses.append(horse)
                horses_collected += 1
                
                print(f"  âœ“ [{horses_collected:3d}] {horse['name_ja']} ({horse['birth_year']}å¹´)")
                
                # ç›®æ¨™é ­æ•°ã«åˆ°é”
                if horses_collected >= max_horses:
                    break
            
            # æ¬¡ã®ãƒšãƒ¼ã‚¸ã¸
            current_page += 1
            position_in_page = 0  # æ¬¡ã®ãƒšãƒ¼ã‚¸ã‹ã‚‰ã¯æœ€åˆã‹ã‚‰
            
            # APIè² è·è»½æ¸›
            time.sleep(1)
        
        print(f"\nâœ… åˆè¨ˆ{len(horses)}é ­ã‚’å–å¾—ã—ã¾ã—ãŸ")
        return horses
    
    def _get_page_horses(self, page: int, limit: int = 100) -> List[Dict]:
        """æŒ‡å®šãƒšãƒ¼ã‚¸ã®é¦¬ãƒªã‚¹ãƒˆã‚’å–å¾—"""
        params = {
            "grade[]": "4",  # G1å‹åˆ©é¦¬
            "sort": "age-desc",  # ç”Ÿå¹´é™é †
            "limit": limit,
            "page": page
        }
        
        try:
            response = self.session.get(self.base_url, params=params)
            response.raise_for_status()
            response.encoding = 'euc-jp'
            
            soup = BeautifulSoup(response.text, 'html.parser')
            return self._parse_horse_list(soup)
            
        except requests.RequestException as e:
            print(f"âŒ ãƒšãƒ¼ã‚¸{page}å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def _parse_horse_list(self, soup: BeautifulSoup) -> List[Dict]:
        """ãƒšãƒ¼ã‚¸ã®HTMLã‹ã‚‰é¦¬æƒ…å ±ã‚’æŠ½å‡º"""
        horses = []
        
        for row in soup.find_all('tr'):
            try:
                # ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã‹ã‚‰é¦¬IDã‚’å–å¾—
                checkbox = row.find('input', {'type': 'checkbox'})
                if not checkbox or 'i-horse_' not in checkbox.get('name', ''):
                    continue
                
                horse_id = checkbox.get('value')
                
                # å„tdã‚’å–å¾—
                tds = row.find_all('td')
                if len(tds) < 4:
                    continue
                
                # é¦¬åã‚’å–å¾—ï¼ˆ2ç•ªç›®ã®tdï¼‰
                name_cell = tds[1].find('a')
                if not name_cell:
                    continue
                name_ja = name_cell.text.strip()
                
                # æ€§åˆ¥ã‚’å–å¾—ï¼ˆ3ç•ªç›®ã®tdï¼‰
                sex = tds[2].text.strip()
                
                # ç”Ÿå¹´ã‚’å–å¾—ï¼ˆ4ç•ªç›®ã®tdï¼‰
                birth_year_link = tds[3].find('a')
                if not birth_year_link:
                    continue
                birth_year = int(birth_year_link.text.strip())
                
                horses.append({
                    'id': int(horse_id),
                    'name_ja': name_ja,
                    'sex': sex,
                    'birth_year': birth_year
                })
                
            except (ValueError, AttributeError):
                continue
        
        return horses


class CompleteBatchProcessor:
    """é¦¬ãƒªã‚¹ãƒˆå–å¾— + è©³ç´°ãƒ‡ãƒ¼ã‚¿å–å¾—ã®å®Œå…¨ãƒãƒƒãƒå‡¦ç†"""
    
    def __init__(self):
        self.list_scraper = SimpleOffsetHorseListScraper()
        # HorseScraperã¯å‹•çš„ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆå¾ªç’°ã‚¤ãƒ³ãƒãƒ¼ãƒˆå›é¿ï¼‰
        self.detail_scraper = None
    
    def _init_detail_scraper(self):
        """HorseScraperã®é…å»¶åˆæœŸåŒ–"""
        if self.detail_scraper is None:
            try:
                from scrapers.horse_scraper import HorseScraper
                self.detail_scraper = HorseScraper()
            except ImportError as e:
                print(f"âš ï¸ HorseScraperã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
                return False
        return True
    
    def collect_and_process_horses(
        self,
        total_target: int = 100,
        batch_size: int = 25,
        start_offset: int = 0,
        min_birth_year: int = 2015,
        process_details: bool = True,
        delay_between_horses: int = 3
    ) -> Dict:
        """
        é¦¬ãƒªã‚¹ãƒˆå–å¾— + è©³ç´°å‡¦ç†ã®å®Œå…¨ãƒãƒƒãƒ
        
        Args:
            total_target: ç›®æ¨™ç·æ•°
            batch_size: ãƒãƒƒãƒã‚µã‚¤ã‚º
            start_offset: é–‹å§‹ã‚ªãƒ•ã‚»ãƒƒãƒˆ
            min_birth_year: æœ€å°ç”Ÿå¹´
            process_details: è©³ç´°ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã™ã‚‹ã‹
            delay_between_horses: é¦¬é–“ã®å‡¦ç†é–“éš”
        
        Returns:
            å‡¦ç†çµæœ
        """
        print("=" * 70)
        print("ğŸ‡ å®Œå…¨ãƒãƒƒãƒå‡¦ç†é–‹å§‹")
        print("=" * 70)
        print(f"ğŸ¯ ç›®æ¨™: {total_target}é ­")
        print(f"ğŸ“¦ ãƒãƒƒãƒã‚µã‚¤ã‚º: {batch_size}é ­")
        print(f"ğŸ“ é–‹å§‹ã‚ªãƒ•ã‚»ãƒƒãƒˆ: {start_offset}")
        print(f"ğŸ“… æœ€å°ç”Ÿå¹´: {min_birth_year}å¹´")
        print(f"ğŸ”§ è©³ç´°å‡¦ç†: {'æœ‰åŠ¹' if process_details else 'ç„¡åŠ¹'}")
        print()
        
        # Step 1: é¦¬ãƒªã‚¹ãƒˆå–å¾—
        print("ğŸ” Step 1: é¦¬ãƒªã‚¹ãƒˆå–å¾—")
        horse_list = self._collect_horse_list(total_target, batch_size, start_offset, min_birth_year)
        
        if not horse_list:
            return {'error': 'é¦¬ãƒªã‚¹ãƒˆå–å¾—ã«å¤±æ•—'}
        
        # çµæœä¿å­˜
        results = {
            'horse_list': horse_list,
            'list_count': len(horse_list),
            'success': [],
            'failed': [],
            'total_processed': 0
        }
        
        # Step 2: è©³ç´°ãƒ‡ãƒ¼ã‚¿å‡¦ç†ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        if process_details and horse_list:
            print(f"\nğŸ” Step 2: è©³ç´°ãƒ‡ãƒ¼ã‚¿å‡¦ç†ï¼ˆ{len(horse_list)}é ­ï¼‰")
            
            if not self._init_detail_scraper():
                print("âŒ è©³ç´°å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
                process_details = False
            else:
                detail_results = self._process_horse_details(horse_list, delay_between_horses)
                results.update(detail_results)
        
        # çµæœã‚µãƒãƒªãƒ¼
        self._print_final_summary(results)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        self._save_results(results)
        
        return results
    
    def _collect_horse_list(self, total_target: int, batch_size: int, start_offset: int, min_birth_year: int) -> List[Dict]:
        """é¦¬ãƒªã‚¹ãƒˆã®åé›†"""
        all_horses = []
        current_offset = start_offset
        
        while len(all_horses) < total_target:
            remaining = total_target - len(all_horses)
            current_batch_size = min(batch_size, remaining)
            
            print(f"ğŸ“¦ ãƒªã‚¹ãƒˆãƒãƒƒãƒ: ã‚ªãƒ•ã‚»ãƒƒãƒˆ{current_offset}, {current_batch_size}é ­å–å¾—")
            
            batch_horses = self.list_scraper.get_g1_horses_by_offset(
                offset=current_offset,
                max_horses=current_batch_size,
                min_birth_year=min_birth_year
            )
            
            if not batch_horses:
                print("âš ï¸ ã“ã‚Œä»¥ä¸Šé¦¬ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                break
            
            # é‡è¤‡ãƒã‚§ãƒƒã‚¯
            new_horses = []
            existing_ids = {horse['id'] for horse in all_horses}
            
            for horse in batch_horses:
                if horse['id'] not in existing_ids:
                    new_horses.append(horse)
            
            all_horses.extend(new_horses)
            current_offset += len(batch_horses)
            
            print(f"âœ… ãƒªã‚¹ãƒˆãƒãƒƒãƒå®Œäº†: {len(new_horses)}é ­è¿½åŠ , ç´¯è¨ˆ{len(all_horses)}é ­")
            
            if len(all_horses) < total_target:
                time.sleep(2)
        
        return all_horses
    
    def _process_horse_details(self, horse_list: List[Dict], delay: int) -> Dict:
        """é¦¬ã®è©³ç´°ãƒ‡ãƒ¼ã‚¿å‡¦ç†"""
        results = {
            'success': [],
            'failed': [],
            'total_processed': 0
        }
        
        total = len(horse_list)
        
        for i, horse in enumerate(horse_list, 1):
            horse_id = str(horse['id'])
            horse_name = horse['name_ja']
            
            print(f"ğŸ [{i}/{total}] {horse_name} (ID: {horse_id})")
            
            try:
                success = self.detail_scraper.scrape(horse_id)
                
                if success:
                    results['success'].append({
                        'id': horse_id,
                        'name': horse_name,
                        'processed_at': datetime.now().isoformat()
                    })
                    print(f"    âœ… å®Œäº†")
                else:
                    results['failed'].append({
                        'id': horse_id,
                        'name': horse_name,
                        'error': 'è©³ç´°ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¤±æ•—'
                    })
                    print(f"    âŒ å¤±æ•—")
                
            except Exception as e:
                results['failed'].append({
                    'id': horse_id,
                    'name': horse_name,
                    'error': str(e)
                })
                print(f"    âŒ ã‚¨ãƒ©ãƒ¼: {e}")
            
            results['total_processed'] += 1
            
            # å¾…æ©Ÿï¼ˆæœ€å¾Œä»¥å¤–ï¼‰
            if i < total:
                time.sleep(delay)
        
        return results
    
    def _print_final_summary(self, results: Dict):
        """æœ€çµ‚ã‚µãƒãƒªãƒ¼è¡¨ç¤º"""
        list_count = results.get('list_count', 0)
        success_count = len(results.get('success', []))
        failed_count = len(results.get('failed', []))
        total_processed = results.get('total_processed', 0)
        
        print("\n" + "=" * 70)
        print("ğŸ å®Œå…¨ãƒãƒƒãƒå‡¦ç†å®Œäº†ï¼")
        print("=" * 70)
        print(f"ğŸ“‹ é¦¬ãƒªã‚¹ãƒˆå–å¾—: {list_count}é ­")
        if total_processed > 0:
            print(f"âœ… è©³ç´°å‡¦ç†æˆåŠŸ: {success_count}é ­")
            print(f"âŒ è©³ç´°å‡¦ç†å¤±æ•—: {failed_count}é ­")
            print(f"ğŸ“Š è©³ç´°å‡¦ç†æˆåŠŸç‡: {success_count/total_processed*100:.1f}%")
        print("=" * 70)
    
    def _save_results(self, results: Dict):
        """çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        os.makedirs('outputs', exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"complete_batch_results_{timestamp}.json"
        filepath = os.path.join('outputs', filename)
        
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            print(f"ğŸ“„ çµæœä¿å­˜: {filepath}")
        except Exception as e:
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")


# ä¾¿åˆ©ãªå®Ÿè¡Œé–¢æ•°

def get_next_100_horses(last_processed_count: int = 0) -> List[Dict]:
    """æ¬¡ã®100é ­ã‚’å–å¾—ã™ã‚‹é–¢æ•°"""
    scraper = SimpleOffsetHorseListScraper()
    
    horses = scraper.get_g1_horses_by_offset(
        offset=last_processed_count,
        max_horses=100,
        min_birth_year=2015
    )
    
    return horses

def run_complete_100_horses_batch():
    """100é ­ã®å®Œå…¨ãƒãƒƒãƒå‡¦ç†"""
    processor = CompleteBatchProcessor()
    
    results = processor.collect_and_process_horses(
        total_target=100,
        batch_size=25,
        start_offset=0,
        min_birth_year=2015,
        process_details=True,
        delay_between_horses=3
    )
    
    return results

def run_list_only(target: int = 100, offset: int = 0):
    """ãƒªã‚¹ãƒˆå–å¾—ã®ã¿ï¼ˆè©³ç´°å‡¦ç†ãªã—ï¼‰"""
    processor = CompleteBatchProcessor()
    
    results = processor.collect_and_process_horses(
        total_target=target,
        batch_size=25,
        start_offset=offset,
        min_birth_year=2015,
        process_details=False  # è©³ç´°å‡¦ç†ãªã—
    )
    
    return results


# ãƒ†ã‚¹ãƒˆé–¢æ•°
def test_offset_scraper():
    """ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    print("ğŸ§ª ã‚ªãƒ•ã‚»ãƒƒãƒˆã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ãƒ†ã‚¹ãƒˆ")
    
    scraper = SimpleOffsetHorseListScraper()
    horses = scraper.get_g1_horses_by_offset(
        offset=0,
        max_horses=10,
        min_birth_year=2020
    )
    
    print(f"å–å¾—çµæœ: {len(horses)}é ­")
    
    if horses:
        print("\nğŸ“‹ å–å¾—ã—ãŸé¦¬:")
        for i, horse in enumerate(horses):
            print(f"  {i+1:2d}. {horse['name_ja']} ({horse['birth_year']}å¹´) ID:{horse['id']}")
    
    return horses


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    test_horses = test_offset_scraper()
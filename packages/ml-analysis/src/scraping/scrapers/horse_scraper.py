# src/scraping/scrapers/horse_scraper.py

import sys
import os
from typing import Dict, Optional

# ãƒ‘ã‚¹ã‚’è¿½åŠ 
current_dir = os.path.dirname(os.path.abspath(__file__))
scraping_dir = os.path.dirname(current_dir)
sys.path.append(scraping_dir)

from scrapers.base_scraper import BaseScraper
from extractors.horse.basic_info_extractor import BasicInfoExtractor
from extractors.horse.pedigree_extractor import PedigreeExtractor
from extractors.horse.career_extractor import CareerExtractor
from storage.supabase_storage import SupabaseStorage

class HorseScraper(BaseScraper):
    """é¦¬æƒ…å ±å°‚ç”¨ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼"""
    
    def __init__(self):
        super().__init__()
        
        # å„æŠ½å‡ºã‚¯ãƒ©ã‚¹ã‚’åˆæœŸåŒ–
        self.basic_extractor = BasicInfoExtractor()
        self.pedigree_extractor = PedigreeExtractor()
        self.career_extractor = CareerExtractor()
        
        # ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚¯ãƒ©ã‚¹
        self.storage = SupabaseStorage()
    
    def scrape(self, horse_id: str) -> bool:
        """é¦¬ã®å®Œå…¨ãªæƒ…å ±ã‚’å–å¾—ãƒ»ä¿å­˜"""
        print(f"\n--- é¦¬ID: {horse_id} å®Œå…¨å–å¾—é–‹å§‹ ---")
        
        # 1. åŸºæœ¬æƒ…å ±å–å¾—
        horse_data = self.scrape_horse_detail(horse_id)
        if not horse_data:
            return False
        
        # 2. è¡€çµ±é–¢ä¿‚å–å¾—
        relations = self.pedigree_extractor.extract_relations_from_url(horse_id, self.session)
        
        # 3. è¡€çµ±IDã‚’é¦¬ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ 
        pedigree_ids = self.pedigree_extractor.extract_pedigree_ids_from_relations(relations, horse_id)
        horse_data.update(pedigree_ids)
        
        # 4. ç¨®ä»˜é–¢ä¿‚ã‚’ä½œæˆãƒ»æ›´æ–°ï¼ˆchildren_idsä»˜ãï¼‰
        mating_relations = self.pedigree_extractor.create_mating_relations(pedigree_ids, horse_id, self.storage)
        relations.extend(mating_relations)
        
        # 5. ãƒ‡ãƒ¼ã‚¿ä¿å­˜
        success = self.storage.save_all(horse_data, relations)
        
        print(f"{'âœ…' if success else 'âŒ'} å®Œäº†: {horse_data.get('name_ja', 'Unknown')}")
        
        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆé–“éš”ã‚’ç½®ã
        self.sleep(1)
        
        return success
    
    def scrape_horse_detail(self, horse_id: str) -> Optional[Dict]:
        """å€‹åˆ¥é¦¬ã®è©³ç´°æƒ…å ±ã‚’å–å¾—"""
        detail_url = f"{self.base_url}/horse/{horse_id}/"
        
        soup = self.get_soup(detail_url)
        if not soup:
            return None
        
        try:
            print(f"ğŸ” é¦¬è©³ç´°ãƒšãƒ¼ã‚¸å–å¾—: {horse_id}")
            
            # åŸºæœ¬æƒ…å ±ã‚’æŠ½å‡º
            horse_data = self.basic_extractor.extract(soup, horse_id)
            
            # è¡€çµ±IDã‚’ç›´æ¥å–å¾—
            pedigree_ids = self.pedigree_extractor.extract_pedigree_ids(soup)
            horse_data.update(pedigree_ids)
            
            # ä¸»ãªå‹ã¡éã‚’æŠ½å‡º
            victories = self.career_extractor.extract_main_victories(soup)
            if victories:
                horse_data['main_victories'] = victories
                print(f"    ğŸ† å‹ã¡éå–å¾—: {len(victories)}ãƒ¬ãƒ¼ã‚¹")
            
            # é€šç®—æˆç¸¾ã‚’æŠ½å‡º
            career_record = self.career_extractor.extract_career_record(soup)
            if career_record:
                horse_data['career_record'] = career_record
                print(f"    ğŸ“Š æˆç¸¾å–å¾—: {career_record}")
            
            print(f"    ğŸ“‹ å–å¾—ãƒ‡ãƒ¼ã‚¿é …ç›®æ•°: {len(horse_data)}")
            print(f"  âœ… åŸºæœ¬æƒ…å ±å–å¾—æˆåŠŸ: {horse_data.get('name_ja', 'Unknown')}")
            
            return horse_data
            
        except Exception as e:
            print(f"  âŒ è©³ç´°å–å¾—ã‚¨ãƒ©ãƒ¼ (é¦¬ID: {horse_id}): {e}")
            return None

# ä½¿ç”¨ä¾‹
if __name__ == "__main__":
    scraper = HorseScraper()
    
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œï¼ˆã‚¤ã‚¯ã‚¤ãƒãƒƒã‚¯ã‚¹ï¼‰
    test_horse_id = "2019105219"
    success = scraper.scrape(test_horse_id)
    
    if success:
        print("ğŸ‰ è©³ç´°æƒ…å ±å–å¾—å®Œäº†ï¼")
    else:
        print("âŒ å–å¾—å¤±æ•—")
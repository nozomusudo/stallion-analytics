# src/scraping/scrapers/base_scraper.py

import requests
from bs4 import BeautifulSoup
import time
from typing import Optional
from abc import ABC, abstractmethod

class BaseScraper(ABC):
    """ç«¶é¦¬ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã®åŸºåº•ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, base_url: str = "https://db.netkeiba.com"):
        self.base_url = base_url
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
    
    def get_soup(self, url: str) -> Optional[BeautifulSoup]:
        """URLã‹ã‚‰BeautifulSoupã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å–å¾—"""
        try:
            print(f"ğŸ” ãƒšãƒ¼ã‚¸å–å¾—: {url}")
            response = self.session.get(url, timeout=15)
            response.raise_for_status()
            response.encoding = 'euc-jp'
            
            soup = BeautifulSoup(response.text, 'html.parser')
            return soup
            
        except Exception as e:
            print(f"âŒ ãƒšãƒ¼ã‚¸å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def sleep(self, seconds: int = 1):
        """ãƒªã‚¯ã‚¨ã‚¹ãƒˆé–“éš”åˆ¶å¾¡"""
        time.sleep(seconds)
    
    @abstractmethod
    def scrape(self, target_id: str):
        """ã‚µãƒ–ã‚¯ãƒ©ã‚¹ã§å®Ÿè£…ã™ã‚‹æŠ½å‡ºãƒ¡ã‚½ãƒƒãƒ‰"""
        pass
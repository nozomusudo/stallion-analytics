"""
ç«¶é¦¬ãƒ‡ãƒ¼ã‚¿ä¸€æ‹¬å–å¾—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
HorseListScraperã¨HorseScraperã‚’çµ„ã¿åˆã‚ã›ã¦åŠ¹ç‡çš„ã«ãƒ‡ãƒ¼ã‚¿åé›†
"""

import sys
import os
import time
from typing import List, Dict, Optional
from datetime import datetime
import json

# ãƒ‘ã‚¹è¨­å®šï¼ˆJupyterç”¨ï¼‰
current_dir = os.getcwd()
src_path = os.path.join(current_dir, 'src', 'scraping')
if src_path not in sys.path:
    sys.path.append(src_path)

# è‡ªä½œãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from horse_list_scraper import HorseListScraper
from scrapers.horse_scraper import HorseScraper


class HorseBatchScraper:
    """é¦¬ãƒ‡ãƒ¼ã‚¿ã®ä¸€æ‹¬å–å¾—ãƒ»ä¿å­˜ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.list_scraper = HorseListScraper()
        self.detail_scraper = HorseScraper()
        self.results = {
            'success': [],
            'failed': [],
            'skipped': [],
            'total_processed': 0
        }
    
    def run_batch_collection(
        self, 
        max_horses: int = 10,
        min_birth_year: int = 2018,
        skip_existing: bool = True,
        delay_between_horses: int = 2
    ) -> Dict:
        """
        é¦¬ãƒ‡ãƒ¼ã‚¿ã®ä¸€æ‹¬åé›†å®Ÿè¡Œ
        
        Args:
            max_horses: å‡¦ç†ã™ã‚‹æœ€å¤§é¦¬æ•°
            min_birth_year: å¯¾è±¡æœ€å°ç”Ÿå¹´
            skip_existing: æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ã‹
            delay_between_horses: é¦¬ã”ã¨ã®å‡¦ç†é–“éš”ï¼ˆç§’ï¼‰
        
        Returns:
            å‡¦ç†çµæœã®è¾æ›¸
        """
        print("=" * 60)
        print("ğŸ‡ ç«¶é¦¬ãƒ‡ãƒ¼ã‚¿ä¸€æ‹¬åé›†é–‹å§‹")
        print("=" * 60)
        print(f"ğŸ“‹ è¨­å®š:")
        print(f"   - å¯¾è±¡é¦¬æ•°: {max_horses}é ­")
        print(f"   - å¯¾è±¡ç”Ÿå¹´: {min_birth_year}å¹´ä»¥é™")
        print(f"   - æ—¢å­˜ã‚¹ã‚­ãƒƒãƒ—: {'æœ‰åŠ¹' if skip_existing else 'ç„¡åŠ¹'}")
        print(f"   - å‡¦ç†é–“éš”: {delay_between_horses}ç§’")
        print()
        
        # ã‚¹ãƒ†ãƒƒãƒ—1: G1é¦¬ãƒªã‚¹ãƒˆå–å¾—
        print("ğŸ” ã‚¹ãƒ†ãƒƒãƒ—1: G1é¦¬ãƒªã‚¹ãƒˆå–å¾—")
        horse_list = self.list_scraper.scrape_g1_horses(
            max_horses=max_horses, 
            min_birth_year=min_birth_year
        )
        
        if not horse_list:
            print("âŒ G1é¦¬ãƒªã‚¹ãƒˆã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return self.results
        
        print(f"âœ… {len(horse_list)}é ­ã®å€™è£œé¦¬ã‚’å–å¾—")
        print()
        
        # ã‚¹ãƒ†ãƒƒãƒ—2: æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®ãƒã‚§ãƒƒã‚¯ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        if skip_existing:
            horse_list = self._filter_existing_horses(horse_list)
            print(f"ğŸ“‹ ã‚¹ã‚­ãƒƒãƒ—å¾Œ: {len(horse_list)}é ­ãŒå‡¦ç†å¯¾è±¡")
            print()
        
        # ã‚¹ãƒ†ãƒƒãƒ—3: è©³ç´°ãƒ‡ãƒ¼ã‚¿å–å¾—
        print("ğŸ” ã‚¹ãƒ†ãƒƒãƒ—3: å„é¦¬ã®è©³ç´°ãƒ‡ãƒ¼ã‚¿å–å¾—")
        self._process_horses_details(horse_list, delay_between_horses)
        
        # çµæœã‚µãƒãƒªãƒ¼
        self._print_results_summary()
        
        return self.results
    
    def _filter_existing_horses(self, horse_list: List[Dict]) -> List[Dict]:
        """æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã—ã¦é‡è¤‡ã‚’é¿ã‘ã‚‹"""
        if not self.list_scraper.supabase:
            print("âš ï¸ SupabaseãŒåˆ©ç”¨ã§ããªã„ãŸã‚ã€é‡è¤‡ãƒã‚§ãƒƒã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
            return horse_list
        
        try:
            # æ—¢å­˜ã®é¦¬IDã‚’å–å¾—
            existing_response = self.list_scraper.supabase.table('horses').select('id').execute()
            existing_ids = {row['id'] for row in existing_response.data}
            
            # æ–°ã—ã„é¦¬ã®ã¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
            new_horses = [horse for horse in horse_list if horse['id'] not in existing_ids]
            
            skipped_count = len(horse_list) - len(new_horses)
            if skipped_count > 0:
                print(f"ğŸ“‹ {skipped_count}é ­ã¯æ—¢ã«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«å­˜åœ¨ã™ã‚‹ãŸã‚ã‚¹ã‚­ãƒƒãƒ—")
                self.results['skipped'] = [
                    horse for horse in horse_list if horse['id'] in existing_ids
                ]
            
            return new_horses
            
        except Exception as e:
            print(f"âš ï¸ æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯ã§ã‚¨ãƒ©ãƒ¼: {e}")
            print("   ã™ã¹ã¦ã®é¦¬ã‚’å‡¦ç†å¯¾è±¡ã¨ã—ã¾ã™")
            return horse_list
    
    def _process_horses_details(self, horse_list: List[Dict], delay: int):
        """å„é¦¬ã®è©³ç´°ãƒ‡ãƒ¼ã‚¿ã‚’é †æ¬¡å–å¾—"""
        total = len(horse_list)
        
        for i, horse in enumerate(horse_list, 1):
            horse_id = str(horse['id'])
            horse_name = horse['name_ja']
            
            print(f"ğŸ [{i}/{total}] {horse_name} (ID: {horse_id}) å‡¦ç†é–‹å§‹...")
            
            try:
                # è©³ç´°ãƒ‡ãƒ¼ã‚¿å–å¾—
                success = self.detail_scraper.scrape(horse_id)
                
                if success:
                    self.results['success'].append({
                        'id': horse_id,
                        'name': horse_name,
                        'processed_at': datetime.now().isoformat()
                    })
                    print(f"   âœ… å®Œäº†")
                else:
                    self.results['failed'].append({
                        'id': horse_id,
                        'name': horse_name,
                        'error': 'ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¤±æ•—'
                    })
                    print(f"   âŒ å¤±æ•—")
                
            except Exception as e:
                self.results['failed'].append({
                    'id': horse_id,
                    'name': horse_name,
                    'error': str(e)
                })
                print(f"   âŒ ã‚¨ãƒ©ãƒ¼: {e}")
            
            self.results['total_processed'] += 1
            
            # æœ€å¾Œä»¥å¤–ã¯å¾…æ©Ÿ
            if i < total:
                print(f"   â³ {delay}ç§’å¾…æ©Ÿä¸­...")
                time.sleep(delay)
            
            print()
    
    def _print_results_summary(self):
        """å‡¦ç†çµæœã®ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
        success_count = len(self.results['success'])
        failed_count = len(self.results['failed'])
        skipped_count = len(self.results['skipped'])
        total = self.results['total_processed']
        
        print("=" * 60)
        print("ğŸ“Š å‡¦ç†çµæœã‚µãƒãƒªãƒ¼")
        print("=" * 60)
        print(f"âœ… æˆåŠŸ: {success_count}é ­")
        print(f"âŒ å¤±æ•—: {failed_count}é ­") 
        print(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: {skipped_count}é ­")
        print(f"ğŸ“‹ å‡¦ç†æ¸ˆç·æ•°: {total}é ­")
        
        if success_count > 0:
            print(f"\nğŸ‰ æˆåŠŸç‡: {success_count/total*100:.1f}%")
            print("\nâœ… æˆåŠŸã—ãŸé¦¬:")
            for horse in self.results['success']:
                print(f"   - {horse['name']} (ID: {horse['id']})")
        
        if failed_count > 0:
            print(f"\nâŒ å¤±æ•—ã—ãŸé¦¬:")
            for horse in self.results['failed']:
                print(f"   - {horse['name']} (ID: {horse['id']}): {horse['error']}")
        
        print("=" * 60)
    
    def save_results_log(self, filename: Optional[str] = None):
        """å‡¦ç†çµæœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"batch_scraping_results_{timestamp}.json"
        
        filepath = os.path.join('outputs', filename)
        os.makedirs('outputs', exist_ok=True)
        
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(self.results, f, ensure_ascii=False, indent=2)
            print(f"ğŸ“„ çµæœãƒ­ã‚°ã‚’ä¿å­˜: {filepath}")
        except Exception as e:
            print(f"âŒ ãƒ­ã‚°ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")


# Jupyter Notebookç”¨ã®ä¾¿åˆ©é–¢æ•°
def quick_batch_scrape(
    max_horses: int = 10,
    min_birth_year: int = 2020,
    delay: int = 2,
    save_log: bool = True
) -> Dict:
    """
    ã‚¯ã‚¤ãƒƒã‚¯å®Ÿè¡Œç”¨é–¢æ•°ï¼ˆJupyter Notebookå‘ã‘ï¼‰
    
    Args:
        max_horses: å–å¾—ã™ã‚‹é¦¬æ•°
        min_birth_year: æœ€å°ç”Ÿå¹´
        delay: å‡¦ç†é–“éš”ï¼ˆç§’ï¼‰
        save_log: çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹ã‹
    
    Returns:
        å‡¦ç†çµæœ
    """
    scraper = HorseBatchScraper()
    results = scraper.run_batch_collection(
        max_horses=max_horses,
        min_birth_year=min_birth_year,
        delay_between_horses=delay
    )
    
    if save_log:
        scraper.save_results_log()
    
    return results


# ä½¿ç”¨ä¾‹
if __name__ == "__main__":
    # 10é ­ã§ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    batch_scraper = HorseBatchScraper()
    results = batch_scraper.run_batch_collection(
        max_horses=10,
        min_birth_year=2020,
        delay_between_horses=2
    )
    
    # çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    batch_scraper.save_results_log()